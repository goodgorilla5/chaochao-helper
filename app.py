import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
import io

st.set_page_config(page_title="ç‡•å·¢-å°åŒ—è‡ªå‹•åŠ©æ‰‹", layout="centered")

def process_logic(content):
    """è§£æ SCP è³‡æ–™çš„æ ¸å¿ƒé‚è¼¯"""
    clean_content = content.replace('+', ' ')
    elements = clean_content.split()
    final_rows = []
    current_row = []
    for item in elements:
        if item.startswith('A') and current_row:
            if "F22" in current_row:
                try:
                    cleaned = {
                        "å°ä»£": str(current_row[3])[-3:],
                        "ä»¶æ•¸": int(current_row[5].lstrip('0') or 0),
                        "å…¬æ–¤": int(current_row[6].lstrip('0') or 0),
                        "å–®åƒ¹": int(current_row[7].lstrip('0')[:-1] or 0),
                        "è²·å®¶": str(current_row[-1])
                    }
                    final_rows.append(cleaned)
                except: pass
            current_row = []
        if len(item) > 3 and item[0:2].isdigit() and item[2].isalpha():
            current_row.append(item[:2]); current_row.append(item[2:])
        else:
            current_row.append(item)
    return final_rows

def auto_fetch():
    """æ¨¡æ“¬çœŸå¯¦é»æ“Šä¸‹è¼‰çš„å‡½æ•¸"""
    url = "https://amis.afa.gov.tw/download/DownloadVegFruitCoopData2.aspx"
    session = requests.Session()
    # å½è£æˆä¸€èˆ¬çš„é›»è…¦ç€è¦½å™¨
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    })
    
    try:
        # ç¬¬ä¸€æ­¥ï¼šç²å–ç¶²é ï¼Œæ‹¿åˆ°é»æ“Šå‹•ä½œå¿…å‚™çš„éš±è—ã€Œé–€ç¥¨ã€
        r1 = session.get(url, timeout=15)
        soup = BeautifulSoup(r1.text, 'html.parser')
        
        # é€™äº›æ˜¯é»æ“Šå‹•ä½œçš„é—œéµåƒæ•¸
        payload = {
            '__VIEWSTATE': soup.find('input', {'name': '__VIEWSTATE'})['value'],
            '__VIEWSTATEGENERATOR': soup.find('input', {'name': '__VIEWSTATEGENERATOR'})['value'],
            '__EVENTVALIDATION': soup.find('input', {'name': '__EVENTVALIDATION'})['value'],
            'ctl00$content$lstMarket': '104', # å°åŒ—
            'ctl00$content$txtUnit': 'S00076', # ç‡•å·¢è¾²æœƒ
            'ctl00$content$rdoFileFormat': '4', # SCPæ ¼å¼
            'ctl00$content$btnDownload': 'ä¸‹è¼‰' # æ¨¡æ“¬é»æ“Šä¸‹è¼‰æŒ‰éˆ•
        }
        
        # ç¬¬äºŒæ­¥ï¼šç™¼é€é»æ“Šä¿¡è™Ÿ
        r2 = session.post(url, data=payload, timeout=20)
        
        if r2.status_code == 200 and "A11" in r2.text:
            return r2.text
        else:
            return None
    except Exception as e:
        return f"Error: {e}"

# --- ç¶²é ä»‹é¢ ---
st.title("ğŸš€ ç‡•å·¢-å°åŒ—ä¸€éµåŒæ­¥")

if st.button("ğŸ”´ é»æˆ‘è‡ªå‹•æŠ“å–æœ€æ–°è³‡æ–™", use_container_width=True):
    with st.spinner("æ­£åœ¨æ¨¡æ“¬é»æ“Šä¸‹è¼‰ä¸­..."):
        result = auto_fetch()
        if result and not str(result).startswith("Error"):
            st.session_state['data'] = result
            st.success("åŒæ­¥æˆåŠŸï¼")
        else:
            st.error("è‡ªå‹•æŠ“å–å¤±æ•—ï¼Œå¯èƒ½æ˜¯è¾²å§”æœƒç¶²ç«™é˜»æ“‹äº†åœ‹å¤–ä¼ºæœå™¨çš„æ¨¡æ“¬é»æ“Šã€‚")

# é¡¯ç¤ºå€
if 'data' in st.session_state:
    df = pd.DataFrame(process_logic(st.session_state['data']))
    if not df.empty:
        st.divider()
        q = st.text_input("ğŸ” æœå°‹å°ä»£")
        if q: df = df[df['å°ä»£'].str.contains(q)]
        df = df.sort_values(by="å–®åƒ¹", ascending=False)
        
        st.dataframe(df, use_container_width=True, height=500)
        st.metric("ç¸½è¨ˆä»¶æ•¸", f"{df['ä»¶æ•¸'].sum()} ä»¶")

st.markdown("---")
st.write("å¦‚æœè‡ªå‹•æŠ“å–å¤±æ•—ï¼Œè«‹åƒè€ƒä¹‹å‰çš„ã€æ‰‹å‹•ä¸‹è¼‰ã€æ–¹æ¡ˆã€‚")