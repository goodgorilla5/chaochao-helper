import streamlit as st
import pandas as pd
import re
import requests

st.set_page_config(page_title="ç‡•å·¢è¡Œæƒ…(çˆ¶æ¯å°ˆç”¨ç‰ˆ)", layout="centered")

# --- è§£æé‚è¼¯ (ä¿ç•™ä½ æœ€å®Œç¾çš„ç‰ˆæœ¬) ---
def process_logic(content):
    final_rows = []
    grade_map = {"1": "ç‰¹", "2": "å„ª", "3": "è‰¯"}
    # æ”¹ç”¨æ›´å¼·å£¯çš„åˆ†å‰²æ³•ï¼Œæ‡‰å°æ‰€æœ‰ç©ºæ ¼å•é¡Œ
    parts = content.split('F22')
    for p in parts[1:]:
        if "S00076" in p:
            try:
                date_match = re.search(r"(\d{7,8}1)", p)
                if not date_match: continue
                date_pos = date_match.start()
                # æµæ°´è™Ÿåˆä½µ
                serial = p[:date_pos].strip().replace(" ", "")
                # æå–ç­‰ç´šã€å°ä»£
                s_pos = p.find("S00076")
                level = grade_map.get(p[s_pos-2], p[s_pos-2])
                sub_id = p[s_pos+6:s_pos+9]
                # æ•¸å­—å€
                nums = p.split('+')
                pieces = int(nums[0][-3:].lstrip('0') or 0)
                weight = int(nums[1].lstrip('0') or 0)
                price = int(nums[2].lstrip('0')[:-1] or 0) # 00900 -> 90
                buyer = nums[5].strip()[:4]

                final_rows.append({
                    "æµæ°´è™Ÿ": serial, "ç­‰ç´š": level, "å°ä»£": sub_id,
                    "ä»¶æ•¸": pieces, "å…¬æ–¤": weight, "å–®åƒ¹": price, "è²·å®¶": buyer
                })
            except: continue
    return final_rows

st.title("ğŸ ç‡•å·¢-å°åŒ—ç¾å ´å°å¸³")

# --- æ ¸å¿ƒï¼šå˜—è©¦å¾ GitHub è®€å–è‡ªå‹•æŠ“å–çš„æª”æ¡ˆ ---
# æ³¨æ„ï¼šé€™è£¡çš„ç¶²å€ä¹‹å¾Œè¦æ›æˆä½  GitHub å­˜æ”¾ SCP çš„ Raw é€£çµ
AUTO_FILE_URL = "ä½ çš„GITHUB_RAW_é€£çµ" 

@st.cache_data(ttl=3600) # æ¯å°æ™‚è‡ªå‹•åˆ·æ–°ä¸€æ¬¡
def load_auto_data():
    try:
        resp = requests.get(AUTO_FILE_URL, timeout=5)
        if resp.status_code == 200:
            return resp.content.decode("big5", errors="ignore")
    except:
        return None
    return None

content = load_auto_data()

# å¦‚æœè‡ªå‹•è®€å–å¤±æ•—ï¼Œæ‰é¡¯ç¤ºä¸Šå‚³æŒ‰éˆ• (å‚™ç”¨)
if not content:
    uploaded_file = st.file_uploader("è‡ªå‹•è®€å–å¤±æ•—ï¼Œè«‹æ‰‹å‹•ä¸Šå‚³", type=['scp', 'txt'])
    if uploaded_file:
        content = uploaded_file.read().decode("big5", errors="ignore")

if content:
    data = process_logic(content)
    if data:
        df = pd.DataFrame(data)
        
        # çˆ¶æ¯å°ˆç”¨ï¼šå¤§å­—é«”é¡¯ç¤º
        search_query = st.text_input("ğŸ” è¼¸å…¥å°ä»£è™ŸæŸ¥è©¢ (ä¾‹å¦‚ 605)", "")
        
        if search_query:
            df = df[df['å°ä»£'].str.contains(search_query)]
        
        # é è¨­å–®åƒ¹ç”±é«˜åˆ°ä½æ’åº
        df = df.sort_values(by="å–®åƒ¹", ascending=False)

        st.subheader("ğŸ“‹ ä»Šæ—¥è¡Œæƒ…æ˜ç´°")
        st.dataframe(df[["ç­‰ç´š", "å°ä»£", "ä»¶æ•¸", "å–®åƒ¹", "è²·å®¶"]], use_container_width=True)
        
        st.success(f"è®€å–æˆåŠŸï¼ç•¶å‰ F22 ç¸½è¨ˆ: {df['ä»¶æ•¸'].sum()} ä»¶")