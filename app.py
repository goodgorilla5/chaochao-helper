import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup

st.set_page_config(page_title="ç‡•å·¢-å°åŒ—æ·±åº¦åŠ©æ‰‹", layout="centered")

def process_logic(content):
    clean_content = content.replace('+', ' ')
    elements = clean_content.split()
    final_rows = []
    current_row = []
    for item in elements:
        if item.startswith('A') and current_row:
            if "F22" in current_row:
                try:
                    cleaned = {
                        "å°ä»£": str(current_row[3])[-3:],
                        "ä»¶æ•¸": int(current_row[5].lstrip('0') or 0),
                        "å…¬æ–¤": int(current_row[6].lstrip('0') or 0),
                        "å–®åƒ¹": int(current_row[7].lstrip('0')[:-1] or 0),
                        "è²·å®¶": str(current_row[-1])
                    }
                    final_rows.append(cleaned)
                except: pass
            current_row = []
        if len(item) > 3 and item[0:2].isdigit() and item[2].isalpha():
            current_row.append(item[:2]); current_row.append(item[2:])
        else:
            current_row.append(item)
    return final_rows

def deep_fetch():
    url = "https://amis.afa.gov.tw/download/DownloadVegFruitCoopData2.aspx"
    session = requests.Session()
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Referer': url
    })
    
    try:
        # ç¬¬ä¸€æ­¥ï¼šé€²å…¥é é¢æ‹¿åˆ°é–€ç¥¨
        res1 = session.get(url, timeout=15)
        soup = BeautifulSoup(res1.text, 'html.parser')
        
        # æº–å‚™æ¨¡æ“¬é»æ“Šåƒæ•¸
        # æ³¨æ„ï¼š__EVENTTARGET è¨­ç‚º btnDownloadï¼Œç›´æ¥è·³éé¸å–®é¸å–çš„å‹•æ…‹é™åˆ¶
        payload = {
            '__VIEWSTATE': soup.find('input', {'name': '__VIEWSTATE'})['value'],
            '__VIEWSTATEGENERATOR': soup.find('input', {'name': '__VIEWSTATEGENERATOR'})['value'],
            '__EVENTVALIDATION': soup.find('input', {'name': '__EVENTVALIDATION'})['value'],
            'ctl00$content$lstMarket': '104',              # å°åŒ—
            'ctl00$content$txtUnit': 'S00076',             # ç›´æ¥å¡«å…¥ä»£è™Ÿ (å˜—è©¦ç¹éé»æ“Šé¸å–®)
            'ctl00$content$rdoFileFormat': '4',            # SCP æ ¼å¼
            'ctl00$content$btnDownload': 'ä¸‹è¼‰(4ç¢¼å“åä»£ç¢¼)'  # æ¨¡æ“¬æŒ‰ä¸‹é‚£å€‹æŒ‰éˆ•
        }
        
        # ç¬¬äºŒæ­¥ï¼šç›´æ¥ç™¼é€ä¸‹è¼‰è«‹æ±‚
        res2 = session.post(url, data=payload, timeout=25)
        
        if res2.status_code == 200 and "A11" in res2.text:
            return res2.text
        else:
            return None
    except Exception as e:
        return None

# --- UI ä»‹é¢ ---
st.title("ğŸ ç‡•å·¢-å°åŒ—æ·±åº¦åŒæ­¥")
st.write("é€™æœƒå˜—è©¦ç¹éç¶²é é™åˆ¶ï¼Œç›´æ¥é»æ“Šä¸‹è¼‰æŒ‰éˆ•ã€‚")

if st.button("ğŸš€ åŸ·è¡Œæ·±åº¦æŠ“å–", use_container_width=True):
    with st.spinner("æ¨¡æ“¬äººå·¥é»æ“Šä¸­..."):
        data_text = deep_fetch()
        if data_text:
            st.session_state['current_data'] = data_text
            st.success("åŒæ­¥æˆåŠŸï¼")
        else:
            st.error("è‡ªå‹•æŠ“å–å—é˜»ã€‚åŸå› ï¼šè©²ç¶²é é¸å–®éœ€è¦æ»‘é¼ å¯¦é«”é»æ“Šè§¸ç™¼ JS è…³æœ¬ã€‚")

if 'current_data' in st.session_state:
    results = process_logic(st.session_state['current_data'])
    if results:
        df = pd.DataFrame(results)
        st.divider()
        q = st.text_input("ğŸ” æœå°‹å°ä»£")
        if q: df = df[df['å°ä»£'].str.contains(q)]
        df = df.sort_values(by="å–®åƒ¹", ascending=False)
        st.dataframe(df, use_container_width=True, height=500)
        st.metric("ç¸½è¨ˆä»¶æ•¸", f"{df['ä»¶æ•¸'].sum()} ä»¶")

st.markdown("---")
st.caption("è¨»ï¼šè‹¥æŒçºŒå¤±æ•—ï¼Œå»ºè­°ä½¿ç”¨æˆ‘ä¹‹å‰æä¾›çš„ã€JavaScript 1ç§’ä¸‹è¼‰æ›¸ç±¤ã€ï¼Œé‚£æ˜¯ç›®å‰æœ€å¼·çš„ç ´è§£æ³•ã€‚")