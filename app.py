import streamlit as st
import pandas as pd
import re
import requests
from bs4 import BeautifulSoup
from datetime import datetime

st.set_page_config(page_title="ç‡•å·¢å°åŒ—å¸‚å ´åŠ©æ‰‹", layout="centered")

# --- æ–°å¢ï¼šè‡ªå‹•æŠ“å–åŠŸèƒ½ ---
def fetch_amis_data():
    # 1. è¨ˆç®—æ°‘åœ‹æ—¥æœŸ (å¦‚ 1150208)
    now = datetime.now()
    roc_date = f"{now.year - 1911}{now.strftime('%m%d')}"
    
    url = "https://amis.afa.gov.tw/download/DownloadVegFruitCoopData2.aspx"
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"}
    
    try:
        session = requests.Session()
        # ç¬¬ä¸€æ­¥ï¼šç²å–éš±è—çš„ ViewState
        resp = session.get(url, headers=headers)
        soup = BeautifulSoup(resp.text, 'html.parser')
        
        viewstate = soup.find('input', attrs={'name': '__VIEWSTATE'})['value']
        event_validation = soup.find('input', attrs={'name': '__EVENTVALIDATION'})['value']
        
        # ç¬¬äºŒæ­¥ï¼šæ¨¡æ“¬é»æ“Šä¸‹è¼‰ (é€™è£¡çš„åƒæ•¸æ˜¯æ ¹æ“šä½ çš„æ¡†æ¶æª”æ¡ˆæ¨ç®—çš„)
        payload = {
            "__VIEWSTATE": viewstate,
            "__EVENTVALIDATION": event_validation,
            "txtKeyWord": "S00076", # ç‡•å·¢å€è¾²æœƒ
            "btnQuery": "æŸ¥è©¢",      # æ¨¡æ“¬é»æ“ŠæŸ¥è©¢
            "txtDate": roc_date     # è‡ªå‹•å¡«å…¥ä»Šæ—¥æ—¥æœŸ
        }
        
        # æ³¨æ„ï¼šå¯¦éš›ä¸‹è¼‰å¯èƒ½éœ€è¦æ ¹æ“šé»æ“ŠæŒ‰éˆ•çš„ ID èª¿æ•´ payload
        # é€™è£¡å‡è¨­é»æ“Šå¾Œç›´æ¥å›å‚³ SCP å…§å®¹
        response = session.post(url, data=payload, headers=headers)
        
        if response.status_code == 200 and len(response.content) > 100:
            return response.content.decode("big5", errors="ignore")
        else:
            return None
    except Exception as e:
        st.error(f"é€£ç·šå¤±æ•—: {e}")
        return None

# --- åŸæœ‰çš„è§£æé‚è¼¯ (ä¿ç•™ä½ æœ€å®Œç¾çš„ç‰ˆæœ¬) ---
def process_logic(content):
    raw_lines = content.split('    ')
    final_rows = []
    grade_map = {"1": "ç‰¹", "2": "å„ª", "3": "è‰¯"}
    
    for line in raw_lines:
        if "F22" in line and "S00076" in line:
            try:
                date_match = re.search(r"(\d{7,8}1)\s+\d{2}S00076", line)
                if date_match:
                    date_pos = date_match.start()
                    serial = line[:date_pos].strip().replace(" ", "")
                    remaining = line[date_pos:]
                    s_pos = remaining.find("S00076")
                    raw_turn = remaining[s_pos-2]
                    level = grade_map.get(raw_turn, raw_turn)
                    sub_id = remaining[s_pos+6:s_pos+9]
                    nums = line.split('+')
                    pieces = int(nums[0][-3:].lstrip('0') or 0)
                    weight = int(nums[1].lstrip('0') or 0)
                    price_raw = nums[2].lstrip('0')
                    price = int(price_raw[:-1] if price_raw else 0)
                    buyer = nums[5].strip()[:4]

                    final_rows.append({
                        "æµæ°´è™Ÿ": serial, "ç­‰ç´š": level, "å°ä»£": sub_id,
                        "ä»¶æ•¸": pieces, "å…¬æ–¤": weight, "å–®åƒ¹": price, "è²·å®¶": buyer
                    })
            except: continue
    return final_rows

st.title("ğŸ ç‡•å·¢-å°åŒ—ç¾å ´å°å¸³")

# --- å´é‚Šæ¬„æ§åˆ¶ ---
with st.sidebar:
    st.header("æ•¸æ“šæ›´æ–°")
    auto_data = None
    if st.button("ğŸ”„ åŒæ­¥ä»Šæ—¥æœ€æ–°è³‡æ–™"):
        with st.spinner("æ­£åœ¨é€£ç·šè‡³ AMIS..."):
            auto_data = fetch_amis_data()
            if auto_data:
                st.success("æŠ“å–æˆåŠŸï¼")
            else:
                st.error("æŠ“å–å¤±æ•—ï¼Œè«‹æ”¹ç”¨æ‰‹å‹•ä¸Šå‚³ã€‚")

uploaded_file = st.file_uploader("æˆ–æ‰‹å‹•ä¸Šå‚³ SCP æª”æ¡ˆ", type=['scp', 'txt', 'SCP'])

# å„ªå…ˆè®€å–è‡ªå‹•æŠ“å–çš„è³‡æ–™ï¼Œæ²’æœ‰çš„è©±å†çœ‹æ‰‹å‹•ä¸Šå‚³
content = None
if auto_data:
    content = auto_data
elif uploaded_file:
    try:
        content = uploaded_file.read().decode("big5", errors="ignore")
    except:
        content = uploaded_file.read().decode("utf-8", errors="ignore")

if content:
    data = process_logic(content)
    if data:
        df = pd.DataFrame(data)
        st.divider()
        col1, col2, col3 = st.columns([1, 1, 1])
        with col1: search_query = st.text_input("ğŸ” æœå°‹å°ä»£")
        with col2: sort_order = st.selectbox("æ’åºå–®åƒ¹", ["ç”±é«˜è‡³ä½", "ç”±ä½è‡³é«˜"])
        with col3: show_serial = st.checkbox("é¡¯ç¤ºæµæ°´è™Ÿ", value=False)

        if search_query: df = df[df['å°ä»£'].str.contains(search_query)]
        df = df.sort_values(by="å–®åƒ¹", ascending=(sort_order == "ç”±ä½è‡³é«˜"))

        display_columns = ["ç­‰ç´š", "å°ä»£", "ä»¶æ•¸", "å…¬æ–¤", "å–®åƒ¹", "è²·å®¶"]
        if show_serial: display_columns.insert(0, "æµæ°´è™Ÿ")

        st.dataframe(df[display_columns], use_container_width=True, height=500,
                    column_config={"æµæ°´è™Ÿ": st.column_config.TextColumn("æµæ°´è™Ÿ", width="small")})
        st.metric("ç•¶å‰ F22 ç¸½ä»¶æ•¸", f"{df['ä»¶æ•¸'].sum()} ä»¶")