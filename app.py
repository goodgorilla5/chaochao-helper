import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
import datetime

st.set_page_config(page_title="ç‡•å·¢å°åŒ—å°å¸³-è‡ªå‹•å°èˆªç‰ˆ", layout="wide")

# è§£æ SCP å…§å®¹
def parse_scp_content(content):
    final_rows = []
    lines = content.split('\n')
    for line in lines:
        if "F22" in line:
            parts = line.replace('+', ' ').split()
            try:
                final_rows.append({
                    "å°ä»£": str(parts[3])[-3:],
                    "ä»¶æ•¸": int(parts[5].lstrip('0') or 0),
                    "å…¬æ–¤": int(parts[6].lstrip('0') or 0),
                    "å–®åƒ¹": int(parts[7].lstrip('0')[:-1] or 0),
                    "è²·å®¶": parts[-1]
                })
            except: continue
    return final_rows

# æ ¸å¿ƒåŠŸèƒ½ï¼šç›´æ¥å¾ç¶²é æŠ“å–æ•¸æ“š
@st.cache_data(ttl=3600)  # å¿«å–åŠŸèƒ½ï¼šä¸€å°æ™‚å…§é‡è¤‡æ‰“é–‹ç¶²é ï¼Œä¸éœ€è¦é‡æ–°æŠ“å–ï¼Œè®€å–è¶…å¿«
def get_latest_data():
    url = "https://amis.afa.gov.tw/download/DownloadVegFruitCoopData2.aspx"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36"
    }
    session = requests.Session()
    try:
        # 1. ç²å–é€šè¡Œè­‰
        res = session.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(res.text, 'html.parser')
        
        # 2. æº–å‚™ PostBack åƒæ•¸
        payload = {
            "__VIEWSTATE": soup.find("input", {"id": "__VIEWSTATE"})['value'],
            "__VIEWSTATEGENERATOR": soup.find("input", {"id": "__VIEWSTATEGENERATOR"})['value'],
            "__EVENTVALIDATION": soup.find("input", {"id": "__EVENTVALIDATION"})['value'],
            "ctl00$contentPlaceHolder$txtSupplyNo": "S00076 ç‡•å·¢å€è¾²æœƒ",
            "ctl00$contentPlaceHolder$hfldSupplyNo": "S00076",
            "ctl00$contentPlaceHolder$btnQuery2": "4ç¢¼å“åä»£ç¢¼" 
        }
        
        # 3. è«‹æ±‚æ•¸æ“š
        post_res = session.post(url, data=payload, headers=headers, timeout=15)
        return parse_scp_content(post_res.text)
    except Exception as e:
        return f"éŒ¯èª¤: {e}"

# --- ä¸»ç¨‹å¼åŸ·è¡Œå€ ---
st.title("ğŸ ç‡•å·¢è¾²æœƒ - å°åŒ—å°å¸³è‡ªå‹•çœ‹æ¿")

# é€™è£¡å°±æ˜¯é—œéµï¼šä¸€é€²ç¶²é ç›´æ¥åŸ·è¡ŒæŠ“å–
with st.spinner("ğŸš€ æ­£åœ¨è‡ªå‹•é€£ç·šè¾²å§”æœƒç²å–æœ€æ–°æ•¸æ“š..."):
    data = get_latest_data()

if isinstance(data, list) and data:
    df = pd.DataFrame(data)
    
    # æœå°‹åŠŸèƒ½ (é€™é‚„æ˜¯è¦ç•™è‘—ï¼Œæ–¹ä¾¿ä½ æ‰¾ç‰¹å®šå°ä»£)
    search = st.sidebar.text_input("ğŸ” æœå°‹å°ä»£å¾Œ3ç¢¼", placeholder="ä¾‹å¦‚: 025")
    if search:
        df = df[df['å°ä»£'].str.contains(search)]
    
    # æ’åºï¼šå–®åƒ¹æœ€é«˜æ’å‰é¢
    df = df.sort_values(by="å–®åƒ¹", ascending=False)

    # é¡¯ç¤ºæ•¸æ“š
    t1, t2, t3 = st.columns(3)
    t1.metric("ä»Šæ—¥ç¸½ä»¶æ•¸", f"{df['ä»¶æ•¸'].sum()} ä»¶")
    t2.metric("å°åŒ—æœ€é«˜åƒ¹", f"{df['å–®åƒ¹'].max()} å…ƒ")
    t3.metric("ç¸½å…¬æ–¤æ•¸", f"{df['å…¬æ–¤'].sum()} kg")

    st.divider()
    st.dataframe(df, use_container_width=True, height=700)
    
    st.caption(f"ğŸ“… è³‡æ–™æ›´æ–°æ™‚é–“ï¼š{datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    st.sidebar.info("è³‡æ–™æ¯å°æ™‚è‡ªå‹•åˆ·æ–°ä¸€æ¬¡ï¼Œè‹¥éœ€å¼·åˆ¶æ›´æ–°è«‹é‡æ–°æ•´ç†ç¶²é ã€‚")

elif isinstance(data, list) and not data:
    st.warning("âš ï¸ ç›®å‰è¾²å§”æœƒç¶²ç«™å°šæœªç”¢ç”Ÿä»Šæ—¥çš„äº¤æ˜“æª”æ¡ˆ (é€šå¸¸åœ¨ä¸­åˆå‰æ›´æ–°)ã€‚")
else:
    st.error(f"âŒ ç³»çµ±é€£ç·šç•°å¸¸ï¼š{data}")